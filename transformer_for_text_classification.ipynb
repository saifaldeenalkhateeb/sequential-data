{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_for_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "920niWiyahuw"
      },
      "source": [
        "from enum import Enum\n",
        "from termcolor import colored\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy\n",
        "import json \n",
        "from json import JSONEncoder, JSONDecoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXCKlPuqdz32"
      },
      "source": [
        "vocab_size = 20000\n",
        "max_tokens = vocab_size\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "sequence_length = 600\n",
        "batch_size=128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcYxVznnjo2T"
      },
      "source": [
        "BatchNormalization doesn’t work well for sequence data. Instead, we’re using the LayerNormalization layer, which normalizes each sequence independently from other sequences in the batch. Like this, in NumPy-like pseudocode:\n",
        "\n",
        "```\n",
        "def layer_normalization(batch_of_sequences):\n",
        "    mean = np.mean(batch_of_sequences, keepdims=True, axis=-1)\n",
        "    variance = np.var(batch_of_sequences, keepdims=True, axis=-1\n",
        "    return (batch_of_sequences - mean) / variance\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "def batch_normalization(batch_of_images):\n",
        "    mean = np.mean(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
        "    variance = np.var(batch_of_images, keepdims=True, axis=(0, 1, 2))\n",
        "    return (batch_of_images - mean) / variance\n",
        "```\n",
        "\n",
        "While BatchNormalization collects information from many samples to obtain accurate statistics for the features means and variances, LayerNormalization only pools data within each sequence separately, which is more appropriate for sequence data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn-LerH_d71F"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BD0ptvatZbk"
      },
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgCmodvwtcOM"
      },
      "source": [
        "**Using positional encoding to reinject order information**\n",
        "\n",
        "> The idea behind positional encoding is very simple: to give the model access to word order information, we’re going to add to each word embedding the word’s position in the sentence. Our input word embeddings will have two components: the usual word vector, which represents the word independently of any specific context, and a position vector, which represents the position of the word in the current sentence. Hopefully, the model will then figure out how to best leverage this additional information.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> The simplest scheme you could come up with would be to concatenate the word’s position to its embedding vector. You’d add a \"position\" axis to the vector, and fill it with 0 for the first word in the sequence, 1 for the second one, and so on.\n",
        "\n",
        "> That may not be ideal, however, because your positions can potentially be very large integers, which will disrupt the range of values in the embedding vector. As you know, neural networks don’t like very large input values, or discrete input distributions.\n",
        "\n",
        "> The original \"Attention is all you need paper\" used an interesting trick to encode word positions: it added to the word embeddings a vector containing values in the range [-1, 1] that varied cyclically depending on the position (it used cosine functions to achieve this). This trick offers a way to uniquely characterize any integer in a large range via of vector of small values. It’s clever, but it’s not what we’re going to use in our case. We’ll do something simpler and more effective: we’ll just learn position embedding vectors, just the same way we learn to embed word indices. We’ll then proceed to add our position embeddings to the corresponding word embeddings, to obtain a position-aware word embedding. This technique is called \"positional embedding\". Let’s implement it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rerGGxJklnOi"
      },
      "source": [
        "class Text_Vectorization(Enum):\n",
        "    def unigram_int():\n",
        "        return TextVectorization(\n",
        "            max_tokens=max_tokens,\n",
        "            output_mode=\"int\",\n",
        "            output_sequence_length=sequence_length,\n",
        "        )\n",
        "    \n",
        "DATA = {\n",
        "        'unigram_int': Text_Vectorization.unigram_int()\n",
        "    }\n",
        "    \n",
        "class TransformerSetting:\n",
        "    def __init__(self,\n",
        "                 text_vectorization: str,\n",
        "                 num_heads: int,\n",
        "                 dense_dim: int,\n",
        "                 sequence_length: int,\n",
        "                 input_dim = 20000, \n",
        "                 output_dim = 256,\n",
        "                 is_using_positional_embedding: bool = False,\n",
        "                 is_using_positional_encoding: bool = False,  \n",
        "                ):\n",
        "      self.text_vectorization = text_vectorization\n",
        "      self.num_heads = num_heads\n",
        "      self.dense_dim = dense_dim\n",
        "      self.sequence_length  = sequence_length \n",
        "      self.input_dim = input_dim\n",
        "      self.output_dim = output_dim\n",
        "      self.is_using_positional_embedding = is_using_positional_embedding\n",
        "      self.is_using_positional_encoding = is_using_positional_encoding\n",
        "          \n",
        "  \n",
        "    def text_vectorization_func(self):\n",
        "      return DATA[self.text_vectorization]\n",
        "    \n",
        "    def name(self):\n",
        "        model_name = \"\"\n",
        "        if self.text_vectorization is not None:\n",
        "          model_name += f\"{self.text_vectorization}_\"\n",
        "        else:\n",
        "            raise ValueError(\"text_vectorization_name musst be specified...\")\n",
        "        model_name+= f\"dense_dim_{self.dense_dim}_\"\n",
        "        model_name+= f\"num_heads_{self.num_heads}_\"\n",
        "        if sequence_length is not None:\n",
        "          model_name += f\"sequence_length_{sequence_length}_\" \n",
        "        model_name+= f\"input_dim_{self.input_dim}_\"\n",
        "        model_name+= f\"output_dim_{self.output_dim}_\"\n",
        "        if self.is_using_positional_embedding:\n",
        "          model_name += \"using_positional_embedding_\"\n",
        "        if self.is_using_positional_encoding:\n",
        "          model_name += \"using_positional_encoding_\"\n",
        "        model_name+= \"transformer_model\"\n",
        "       \n",
        "        return model_name\n",
        "class TransformerSettingEncoder(JSONEncoder):\n",
        "        def default(self, o):\n",
        "            return o.__dict__\n",
        "        \n",
        "\n",
        "def decode_transformer_setting(dct):\n",
        "    return TransformerSetting(\n",
        "        text_vectorization = dct[\"text_vectorization\"],\n",
        "        num_heads = dct[\"num_heads\"],\n",
        "        dense_dim = dct[\"dense_dim\"],\n",
        "        input_dim = dct[\"input_dim\"],\n",
        "        output_dim = dct[\"output_dim\"],\n",
        "        sequence_length  = dct[\"sequence_length\" ],\n",
        "        is_using_positional_embedding = dct[\"is_using_positional_embedding\"],\n",
        "        is_using_positional_encoding = dct[\"is_using_positional_encoding\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNKArECDlVn7"
      },
      "source": [
        "class IMDB_REVIEWING_ANALYSIS_WORD_AS_SEQUENCE:\n",
        "    \n",
        "    def __init__(self, setting: TransformerSetting):\n",
        "        self.setting = setting\n",
        "        self.load_datasets()\n",
        "        self.build_validation_directory_and_fill_it()\n",
        "        self.text_vectorization = self.setting.text_vectorization_func()\n",
        "        self.prepaire_datasets()\n",
        "        self.model = self.build_model(setting)\n",
        "\n",
        "    def load_datasets(self):\n",
        "        if not os.path.exists('aclImdb'):\n",
        "          if not os.path.exists('aclImdb_v1.tar.gz'):\n",
        "            !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "          !tar -xf aclImdb_v1.tar.gz\n",
        "          !rm -r aclImdb/train/unsup\n",
        "        \n",
        "    \n",
        "    def build_validation_directory_and_fill_it(self):\n",
        "        base_dir = pathlib.Path(\"aclImdb\")\n",
        "        val_dir = base_dir / \"val\"\n",
        "        train_dir = base_dir / \"train\"\n",
        "\n",
        "        if not os.path.exists(val_dir):\n",
        "\n",
        "            for category in (\"neg\", \"pos\"):\n",
        "\n",
        "                path = val_dir / category\n",
        "                if not os.path.exists(path):\n",
        "                    os.makedirs(path)\n",
        "\n",
        "                files = os.listdir(train_dir / category)\n",
        "                random.Random(1337).shuffle(files)\n",
        "                num_val_samples = int(0.2 * len(files))\n",
        "                val_files = files[-num_val_samples:]\n",
        "\n",
        "                for fname in val_files:\n",
        "                  #src = train_dir / category / fname\n",
        "                  #dst = val_dir / category / fname\n",
        "                  src = '/content/aclImdb/train/'+category+'/'+fname\n",
        "                  dst =  '/content/aclImdb/val/'+category+'/'\n",
        "                  %mv {src} {dst}\n",
        "\n",
        "    def prepaire_datasets(self):\n",
        "        train_ds = keras.preprocessing.text_dataset_from_directory(\n",
        "            \"aclImdb/train\", batch_size=batch_size\n",
        "        )\n",
        "        val_ds = keras.preprocessing.text_dataset_from_directory(\n",
        "            \"aclImdb/val\", batch_size=batch_size\n",
        "        )\n",
        "        test_ds = keras.preprocessing.text_dataset_from_directory(\n",
        "            \"aclImdb/test\", batch_size=batch_size\n",
        "        )\n",
        "        \n",
        "        text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "        self.text_vectorization.adapt(text_only_train_ds)\n",
        "        \n",
        "        self.prepaired_train_ds = train_ds.map(lambda x, y: (self.text_vectorization(x), y))\n",
        "        self.prepaired_val_ds = val_ds.map(lambda x, y: (self.text_vectorization(x), y))\n",
        "        self.prepaired_test_ds = test_ds.map(lambda x, y: (self.text_vectorization(x), y))     \n",
        "        \n",
        "    \n",
        "    def set_callbacks(self, callbacks):\n",
        "        self.callbacks = callbacks\n",
        "    \n",
        "    def train_model(self, epochs):\n",
        "        self.history = self.model.fit(\n",
        "            self.prepaired_train_ds.cache(),\n",
        "            validation_data= self.prepaired_val_ds.cache(),\n",
        "            epochs=epochs,\n",
        "            callbacks=self.callbacks)\n",
        "    \n",
        "    def plot_training_curve(self):\n",
        "        plt.plot(self.history.history['accuracy'])\n",
        "        plt.plot(self.history.history['val_accuracy'])\n",
        "        plt.title('using_positional_embedding')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'val'], loc='upper left')\n",
        "        plt.show()\n",
        "    \n",
        "    def load_model(self, model_name):\n",
        "        self.model = keras.models.load_model(model_name)\n",
        "    \n",
        "    def save_training_curve(self, name):\n",
        "        pass\n",
        "    \n",
        "    def get_test_accuracy(self):\n",
        "        print(f\"Test acc: {self.model.evaluate(self.prepaired_test_ds)[1]:.3f}\")\n",
        "    \n",
        "    def forward(self, text: str):\n",
        "        inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "        processed_inputs = self.text_vectorization(inputs)\n",
        "        outputs = self.model(processed_inputs)\n",
        "        inference_model = keras.Model(inputs, outputs)\n",
        "        prepaired_text =  tf.convert_to_tensor([[text],])\n",
        "        return inference_model(prepaired_text)\n",
        "    \n",
        "    def build_model(self, model_setting: TransformerSetting):\n",
        "\n",
        "        inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "        \n",
        "        if self.setting.is_using_positional_embedding:\n",
        "          x = PositionalEmbedding(self.setting.sequence_length, self.setting.input_dim, self.setting.output_dim)(inputs)\n",
        "        elif self.setting.is_using_positional_encoding:\n",
        "          pass\n",
        "        else:\n",
        "          x = layers.Embedding(self.setting.input_dim, self.setting.output_dim)(inputs)\n",
        "        x = TransformerEncoder(self.setting.output_dim, self.setting.dense_dim, self.setting.num_heads)(x)\n",
        "        x = layers.GlobalMaxPooling1D()(x)\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "\n",
        "        outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "        model = keras.Model(inputs, outputs)\n",
        "        model.compile(optimizer=\"rmsprop\",\n",
        "                      loss=\"binary_crossentropy\",\n",
        "                      metrics=[\"accuracy\"])\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlU4JVFivR_K"
      },
      "source": [
        "#with open('settings.json', 'w') as f:\n",
        "#    json.dump(settings, f, indent=4, cls=SettingEncoder)\n",
        "with open(\"transformer_settings.json\") as settings_data:\n",
        "    data = settings_data.read()\n",
        "    settings = json.loads(data, object_hook=decode_transformer_setting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZZRyrl8xThp",
        "outputId": "2a7f0b45-6d6d-4b48-e435-c2651ad66bb9"
      },
      "source": [
        "models = []\n",
        "for setting in settings:\n",
        "    callbacks = [keras.callbacks.ModelCheckpoint(f\"{setting.name()}.keras\", save_best_only=True )]\n",
        "    model = IMDB_REVIEWING_ANALYSIS_WORD_AS_SEQUENCE(setting)\n",
        "    model.set_callbacks(callbacks)\n",
        "    models.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hQBXQ5NOxWgq",
        "outputId": "26d5d9b4-7d06-4d0e-d167-781eae3e1f9c"
      },
      "source": [
        "for model in models:\n",
        "    model.train_model(20)\n",
        "for model in models:\n",
        "    model.plot_training_curve()\n",
        "for model in models:\n",
        "    model.get_test_accuracy()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 50s 307ms/step - loss: 0.6580 - accuracy: 0.6852 - val_loss: 0.4054 - val_accuracy: 0.7954\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.2964 - accuracy: 0.8761 - val_loss: 0.3645 - val_accuracy: 0.8510\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.1970 - accuracy: 0.9226 - val_loss: 0.3115 - val_accuracy: 0.8924\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.1292 - accuracy: 0.9506 - val_loss: 0.3826 - val_accuracy: 0.8878\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0892 - accuracy: 0.9650 - val_loss: 0.4982 - val_accuracy: 0.8762\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0597 - accuracy: 0.9762 - val_loss: 0.5241 - val_accuracy: 0.8840\n",
            "Epoch 7/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0448 - accuracy: 0.9823 - val_loss: 0.5287 - val_accuracy: 0.8832\n",
            "Epoch 8/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0372 - accuracy: 0.9856 - val_loss: 0.6182 - val_accuracy: 0.8758\n",
            "Epoch 9/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 0.6346 - val_accuracy: 0.8754\n",
            "Epoch 10/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.6689 - val_accuracy: 0.8718\n",
            "Epoch 11/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 0.7587 - val_accuracy: 0.8768\n",
            "Epoch 12/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.8642 - val_accuracy: 0.8732\n",
            "Epoch 13/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.9448 - val_accuracy: 0.8740\n",
            "Epoch 14/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.9322 - val_accuracy: 0.8688\n",
            "Epoch 15/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.0481 - val_accuracy: 0.8696\n",
            "Epoch 16/20\n",
            "157/157 [==============================] - 42s 269ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.8939 - val_accuracy: 0.8672\n",
            "Epoch 17/20\n",
            "157/157 [==============================] - 42s 270ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.0212 - val_accuracy: 0.8692\n",
            "Epoch 18/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 1.0784 - val_accuracy: 0.8714\n",
            "Epoch 19/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 1.2019 - val_accuracy: 0.8706\n",
            "Epoch 20/20\n",
            "157/157 [==============================] - 42s 268ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 1.1555 - val_accuracy: 0.8680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "196/196 [==============================] - 23s 118ms/step - loss: 1.5310 - accuracy: 0.8293\n",
            "Test acc: 0.829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhuXqxzh4rXv",
        "outputId": "360f6af9-c888-46ce-ceeb-115c37bf9ecc"
      },
      "source": [
        "for model in models:\n",
        "    model.get_test_accuracy()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196/196 [==============================] - 23s 117ms/step - loss: 1.5310 - accuracy: 0.8293\n",
            "Test acc: 0.829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfOMsdWhxbus"
      },
      "source": [
        "models_with_model_name = {}\n",
        "for model in models:\n",
        "    models_with_model_name['using_positional_embedding'] = model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUyYGKKTxN56"
      },
      "source": [
        "positive_text = \"That was an excellent movie, I loved it.\"\n",
        "negative_text = \"That was a bad movie, I hated it.\"\n",
        "middle1_text = \"That was a bad movie, I loved it.\"\n",
        "middle2_text = \"That was an excellent movie, I hated it.\"\n",
        "minh_text = \"I hated it. That was a sad movie.\"\n",
        "\n",
        "sentences = [positive_text, negative_text, middle1_text, middle2_text, minh_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSpNVeL4xV0h"
      },
      "source": [
        "def convert_to_tensor(text):\n",
        "    return tf.convert_to_tensor([[text],])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3XFv3Kjxe4E"
      },
      "source": [
        "def predict_models(models, text, is_in_tensor: bool):\n",
        "    print(colored(text, 'green'))\n",
        "    for items in models.items():\n",
        "        model_name = items[0]\n",
        "        model = items[1]\n",
        "        if not is_in_tensor:\n",
        "            predictions = model.forward(convert_to_tensor(text))\n",
        "        else: \n",
        "            predictions = model.forward(text)\n",
        "        \n",
        "        print(f\"{model_name}: \", colored(f\"{float(predictions[0] * 100):.2f}\", 'red') + \" percent positive\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boiyJ-THxgn6",
        "outputId": "e57c6485-090d-47a7-a029-1054f55b0462"
      },
      "source": [
        "for sentence in sentences:\n",
        "    predict_models(models_with_model_name, sentence, True)\n",
        "    print(\"- - - - - - - -  - - - - - - - - - \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mThat was an excellent movie, I loved it.\u001b[0m\n",
            "using_positional_embedding:  \u001b[31m6.72\u001b[0m percent positive\n",
            "- - - - - - - -  - - - - - - - - - \n",
            "\u001b[32mThat was a bad movie, I hated it.\u001b[0m\n",
            "using_positional_embedding:  \u001b[31m0.00\u001b[0m percent positive\n",
            "- - - - - - - -  - - - - - - - - - \n",
            "\u001b[32mThat was a bad movie, I loved it.\u001b[0m\n",
            "using_positional_embedding:  \u001b[31m0.24\u001b[0m percent positive\n",
            "- - - - - - - -  - - - - - - - - - \n",
            "\u001b[32mThat was an excellent movie, I hated it.\u001b[0m\n",
            "using_positional_embedding:  \u001b[31m2.94\u001b[0m percent positive\n",
            "- - - - - - - -  - - - - - - - - - \n",
            "\u001b[32mI hated it. That was a sad movie.\u001b[0m\n",
            "using_positional_embedding:  \u001b[31m0.00\u001b[0m percent positive\n",
            "- - - - - - - -  - - - - - - - - - \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgyajQxPAxz-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}